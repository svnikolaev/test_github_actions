# Как решал задачу автоматизации маленький отдел

## Вступление

В начале не было ничего. Потом произошло сотворение мира. Потом потребовалось автоматизировать некоторые процессы рядом с нашим отделом. Вот об этом и будет наша история.

Мы жили тихо-спокойно и никого не трогали. В гости к нам частенько захаживал местный руководитель проектов. Чай-кофе пил, конфет не носил.

Однажды пришел он и спросил, все мы люди – братья? И сказал, что нужно, по-братски, помочь брату братьев, которому вороги задали каждый день мешок большой брать и рис от гречи делить, точнее на веб-страничку заходить, текущую информацию руками забирать, в екселе считать и результат в телеграмм-канал посылать. И работы той так много оказалось, что жизнь бедолаге стала не мила. А я, говорит, как менеджер проектов, вижу, что задача однотипная - можно автоматизировать и спасти брата наших братьев. («Ну что, все уже готово? Как нет?! Ладно, придется перенести дедлайн на вечер, но чтобы больше никаких переносов сроков!» - из фольклора).

Брату братьев мы, конечно же, помогли, сейчас расскажу как.

## Основная часть

Задача поставлена, задача четкая и ясная, а главное – срочная, эксперты на боевых постах, пора надувать шарик.
Как говорится, если у тебя в руках молоток – любая задача кажется гвоздем. В наших руках был python и linux-сервер.
Благодаря удачному стечению обстоятельств оказалось, что из источника данные можно получить с использованием REST API. Всё-таки удобно стоять на плечах гигантов, которые здесь больше не работают.

Если питоном с веб-сервиса нужно что-то забрать по REST API, то всем в голову сразу приходит две библиотеки: http и requests. Requests – библиотека для веб запросов с человеческим лицом, подумали мы, и к чему это нас привело мы с вами скоро узнаем - ружье на стену повесили.

Два прихлопа, три притопа и появился простой скрипт, который мог сходить на эндпоинт, забрать данные, обсчитать и отправить подписчикам. Чтобы ускорить ввод решения в эксплуатацию и расширить круг братьев-коллег, которые при необходимости смогут остановить-запустить задачу коллективным-бессознательным решено использовать планировщик cron, потому что он простой и надежный как трехлинейка.

Пример использования cron:

```sh
$ crontab -l
# Список всех задач
# Информация, которую просят, каждый день в 16:50 отправляется кому надо
50 16 * * * python3 /path/to/simple/scripts/script1.py

$ crontab -e
# Можно отредактировать список в режиме текстового редактирования
# Информация, которую просят, каждый день в 16:50 отправляется кому надо
50 16 * * * python3 /path/to/simple/scripts/script1.py
```

Враг был повержен, все радовались, но не долго.

Возникла другая аналогичная задача, потом еще одна. Через некоторое время стало очевидно, что разные скрипты ходят за данными в одни и те же веб-сервисы, посылают результаты в одни и те же каналы, другими словами - используют один и тот же код. Если этот код нужно изменить, то приходится править одинаковые куски в нескольких файлах. Остро себя показала необходимость обеспечить переиспользование кода – вынести его в общие модули. Проявились сущности: коннекторы - для связи с источниками данных и сервисы – для узкой бизнес-логики отдельно взятой задачи автоматизации.

Уже выстроилась определенная структура проекта:

```text
project/ - корень проекта
├── run_service.py - модуль запуска задач
├── connectors/ - коннекторы до ИС
│   ├── telegram.py
│   ├── connector_1.py
│   ├── connector_2.py
│   └── connector_n.py
└── services/ - задачи (скрипты)
    ├── service_1.py
    ├── service_2.py
    └── service_n.py
```

Задачи (services) теперь запускались через run_service.py, название задачи передавалось, как аргумент. Для парсинга аргументов воспользовались стандартным модулем [argparse](https://docs.python.org/3/library/argparse.html).

Запуск выглядел примерно так:

```sh
python3 /path/to/app/run_service.py service_1
```

Не успели разобраться с одной проблемой, как возникла новая, еще более грозная – на наши сервисы автоматизации стали надеяться, такого удара наш отдел раньше не испытывал никогда.

Оказывается, что некоторые задачи, которые мы автоматизировали, достаточно важные, чтобы пропуск исполнения привлек ненужное внимание. Итоги мозгового штурма разделили нас на два лагеря, одни считали, что нужно утопить проблему в совещаниях, так как задача не профильная, но уже ест много ресурсов, вторые, что нужно быстренько залатать дыру кустарным мониторингом. Затем первые вошли в переговорку и с тех пор их никто не видел, а вторым пришлось перераспределить на себя оставшийся груз, который теперь стал в два раза тяжелее.

Первая часть нашего мониторинга – логи, она по эту сторону баррикад, вторая – алертинг, он по другую сторону. Ходят легенды, что на той стороне уважают стек Grafana-Loki-Promtail, которые подняты в docker с использованием docker-compose, но официально нас там никогда не было и мы ничего об этом не знаем, поэтому говорить о нем не будем.

Поговорим о логах. Для логирования в python есть прекрасный стандартный модуль [logging](https://docs.python.org/3/library/logging.html), который покрывает почти все потребности пользователей. С форматом самих логов все сложнее.

Интернет-разведка донесла, что тема формата логов велика и обильна, а порядка в ней нет и княжит там великий Рандом. Нам не пришлось это по нраву, требовалось установить порядок хотя бы среди своих, тогда мы покопались еще и нашли три зерна:

* [logfmt (logging format)](https://brandur.org/logfmt) – формат логов “ключ=значение”, приятен и машинному глазу и орлиному
* [json (JavaScript Object Notation)](https://www.json.org) – любимец публики, но слишком много болтает, человеку в сыром логе такого формата не только лишь всегда удобно разбираться, но и последнее
* [ltsv (Labeled Tab-separated Values)](http://ltsv.org/) – самое загадочное всех из трех

Первые два семени решили посадить в проект и прорастить, а третье со скупой ностальгической слезой на голубом глазу куда-то унес главный бородач. Назначили logfmt основным форматом, json формат воспроизводится по дополнительному ключу запуска.

Таким образом мы пополнили `run_service.py` дополнительными ключами запуска и общий список стал выглядеть так:

```sh
$ python run_service.py
usage: run_service.py [-h] [-v] [-n] [-t] [Service]

Choose service to start

positional arguments:
  Service          choose service to start

options:
  -h, --help       show this help message and exit
  -v, --verbose    be verbose
  -j, --json       use json format for logging
  -n, --nologfile  do not create a logfile
  -t, --test       use testing config

available services:
  service_1
  service_2
  service_n
```

Долго ли, коротко ли - подошло время торжественного запуска автоматизации версии 2.0. Проект заряжен на сервер, осталось только дождаться отмашки. И тут произошла осечка – питон отсырел и отказался стрелять, ну а точнее версия оказалась слишком низкой и вместо героического запуска мы получили только дым без зеркал. Странно, на нашем компьютере все работало.

Расследование наколенного комитета показало, что новых версий python под установленную на сервере версию linux нет, но эту проблему можно обойти с использованием [docker](https://docs.docker.com/get-started/overview/).

Вариант, который сработал не до конца:

```sh
docker run -it --rm --name run_service -v "$PWD":/usr/src/myapp -w \
/usr/src/myapp python:3.10.2-slim python run_service.py service_name
```

При таком запуске можно выполнять python приложения, которые не требуют сторонних модулей. Настала пора вспомнить про ружье, которое все еще висит на стене. Модуль requests – не часть стандартной библиотеки python, поэтому использовать чистый официальный образ python:3.10 с [hub.docker.com](https://hub.docker.com/_/python) не получится. К тому же мы не застрахованы от того, что завтра нам потребуется еще один, или даже не один, сторонний модуль, что делать? Есть выход, нужно строить свой docker image с гэмблингом и нужными модулями.

Первый Dockerfile комом:

```dockerfile
FROM python:3.10.2-slim
VOLUME [ "/usr/src/app" ]
WORKDIR /usr/src/app
COPY requirements.txt ./
RUN pip install --no-cache-dir -r requirements.txt
CMD ["python3"]
```

Простая команда создания образа:

```sh
docker build -t imagename .
```

Так и сделали, docker-бульон заварили, попробовали, поняли, что чего-то не хватает. Проблема проявилась в том, что теперь файлы с логами и директории, которые появлялись при работе контейнера, создавались с правами суперпользователя, под обычным – ни прочесть, ни удалить. Тогда соль и перец в виде импорта текущего id пользователя при билде образа добавили – стало отлично.

Рабочий Dockerfile:

```dockerfile
FROM python:3.10.2-slim
ARG userid=1000
ARG groupid=1000
RUN groupadd -f -g $groupid user && useradd -o -u $userid -g $groupid user
VOLUME [ "/usr/src/app" ]
WORKDIR /usr/src/app
COPY requirements.txt ./
RUN pip install --no-cache-dir -r requirements.txt
USER user
CMD ["python3"]
```

Команда создания образа с передачей id текущего пользователя и id его группы:

```sh
docker build --build-arg userid=$(id $USER -u) \
--build-arg groupid=$(id $USER -g) -t pythonimp .
```

Вроде все работает. Теперь живем, добра нажить пытаемся.

## Заключение

Можно сказать, что все текущие задачи, которые были поставлены перед началом проекта исполнены: код сервисов переиспользуется, работа приложения логируется, формат логов выбирается из самых модных.

Что можно еще сделать: подумать над возможностью указать директорию вывода логов, но это нужно увязать с использованием docker контейнера, возможно добавить возможность переключать логи между однострочным и многострочным форматом.

Ну вот, как говорится, и я там был, в проект код пилил, от коллег поддержку ловил да как-то пропустил.

[Сам проект](https://github.com/svnikolaev/little_umbrella)
